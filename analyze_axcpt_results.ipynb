{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AX-CPT Results Analysis\n",
    "\n",
    "This notebook provides comprehensive analysis of AX-CPT task results, including:\n",
    "- Behavioral performance metrics (accuracy, reaction times)\n",
    "- Webcam tracking data (blinks, head movement)\n",
    "- Combined analysis of attention and performance\n",
    "\n",
    "**Usage:**\n",
    "1. Run all cells to analyze the most recent session\n",
    "2. Or modify the file paths in Section 1 to analyze specific sessions\n",
    "3. Customize visualizations as needed for your research questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find most recent result files\n",
    "def find_latest_results(results_dir='results'):\n",
    "    \"\"\"\n",
    "    Find the most recent AX-CPT result files.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Paths to trial data, tracking frames, and session summary\n",
    "    \"\"\"\n",
    "    results_path = Path(results_dir)\n",
    "    \n",
    "    if not results_path.exists():\n",
    "        print(f\"‚ùå Results directory '{results_dir}' not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Find all result files\n",
    "    trial_files = sorted(results_path.glob('ax_cpt_results_*.csv'))\n",
    "    tracking_frame_files = sorted(results_path.glob('ax_cpt_tracking_frames_*.csv'))\n",
    "    tracking_session_files = sorted(results_path.glob('ax_cpt_tracking_session_*.csv'))\n",
    "    \n",
    "    if not trial_files:\n",
    "        print(\"‚ùå No result files found!\")\n",
    "        return None\n",
    "    \n",
    "    # Get most recent files\n",
    "    latest_trial = trial_files[-1]\n",
    "    latest_frames = tracking_frame_files[-1] if tracking_frame_files else None\n",
    "    latest_session = tracking_session_files[-1] if tracking_session_files else None\n",
    "    \n",
    "    return {\n",
    "        'trial_data': latest_trial,\n",
    "        'tracking_frames': latest_frames,\n",
    "        'tracking_session': latest_session\n",
    "    }\n",
    "\n",
    "# Find latest results\n",
    "files = find_latest_results()\n",
    "\n",
    "if files:\n",
    "    print(\"\\nüìÅ Found result files:\")\n",
    "    print(f\"  Trial data: {files['trial_data'].name}\")\n",
    "    if files['tracking_frames']:\n",
    "        print(f\"  Tracking frames: {files['tracking_frames'].name}\")\n",
    "    if files['tracking_session']:\n",
    "        print(f\"  Tracking session: {files['tracking_session'].name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "if files:\n",
    "    # Load trial data\n",
    "    df_trials = pd.read_csv(files['trial_data'])\n",
    "    \n",
    "    # Load tracking data if available\n",
    "    df_frames = pd.read_csv(files['tracking_frames']) if files['tracking_frames'] else None\n",
    "    df_session = pd.read_csv(files['tracking_session']) if files['tracking_session'] else None\n",
    "    \n",
    "    # Display basic info\n",
    "    print(\"\\nüìä Data loaded successfully!\")\n",
    "    print(f\"\\nTotal trials: {len(df_trials)}\")\n",
    "    print(f\"Tracking enabled: {'Yes' if df_frames is not None else 'No'}\")\n",
    "    if df_frames is not None:\n",
    "        print(f\"Total frames tracked: {len(df_frames)}\")\n",
    "    \n",
    "    # Show first few rows\n",
    "    print(\"\\nüìã First 5 trials:\")\n",
    "    display(df_trials.head())\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No data to load. Please run the AX-CPT task first to generate results.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Behavioral Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate overall performance metrics\n",
    "if files:\n",
    "    total_trials = len(df_trials)\n",
    "    total_responses = df_trials['response'].sum()\n",
    "    total_correct = df_trials['correct'].sum()\n",
    "    overall_accuracy = (total_correct / total_trials) * 100\n",
    "    response_rate = (total_responses / total_trials) * 100\n",
    "    \n",
    "    # Reaction time stats (only for responses)\n",
    "    rt_data = df_trials[df_trials['reaction_time_ms'].notna()]['reaction_time_ms']\n",
    "    mean_rt = rt_data.mean() if len(rt_data) > 0 else 0\n",
    "    median_rt = rt_data.median() if len(rt_data) > 0 else 0\n",
    "    std_rt = rt_data.std() if len(rt_data) > 0 else 0\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_stats = pd.DataFrame({\n",
    "        'Metric': ['Total Trials', 'Response Rate', 'Overall Accuracy', 'Mean RT (ms)', 'Median RT (ms)', 'RT Std Dev (ms)'],\n",
    "        'Value': [\n",
    "            total_trials,\n",
    "            f\"{response_rate:.1f}%\",\n",
    "            f\"{overall_accuracy:.1f}%\",\n",
    "            f\"{mean_rt:.1f}\",\n",
    "            f\"{median_rt:.1f}\",\n",
    "            f\"{std_rt:.1f}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"\\nüìà Overall Performance Summary\")\n",
    "    print(\"=\" * 40)\n",
    "    display(summary_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Performance by Trial Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate performance by trial type\n",
    "if files:\n",
    "    # Group by trial type\n",
    "    trial_type_stats = df_trials.groupby('trial_type').agg({\n",
    "        'trial_index': 'count',\n",
    "        'response': 'sum',\n",
    "        'correct': 'sum',\n",
    "        'reaction_time_ms': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    trial_type_stats.columns = ['Count', 'Responses', 'Correct', 'Mean RT', 'RT Std']\n",
    "    trial_type_stats['Accuracy %'] = (trial_type_stats['Correct'] / trial_type_stats['Count'] * 100).round(1)\n",
    "    trial_type_stats['Response Rate %'] = (trial_type_stats['Responses'] / trial_type_stats['Count'] * 100).round(1)\n",
    "    \n",
    "    print(\"\\nüìä Performance by Trial Type\")\n",
    "    print(\"=\" * 60)\n",
    "    display(trial_type_stats)\n",
    "    \n",
    "    # Visualize accuracy by trial type\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Accuracy bar chart\n",
    "    ax1 = axes[0]\n",
    "    trial_types = trial_type_stats.index\n",
    "    accuracies = trial_type_stats['Accuracy %']\n",
    "    colors = ['#2ecc71' if acc >= 80 else '#e74c3c' if acc < 60 else '#f39c12' for acc in accuracies]\n",
    "    \n",
    "    bars = ax1.bar(trial_types, accuracies, color=colors, alpha=0.7, edgecolor='black')\n",
    "    ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_xlabel('Trial Type', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Accuracy by Trial Type', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylim(0, 105)\n",
    "    ax1.axhline(y=80, color='gray', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "                f'{height:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    ax1.legend()\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Reaction time by trial type\n",
    "    ax2 = axes[1]\n",
    "    rt_by_type = df_trials[df_trials['reaction_time_ms'].notna()]\n",
    "    if len(rt_by_type) > 0:\n",
    "        sns.boxplot(data=rt_by_type, x='trial_type', y='reaction_time_ms', ax=ax2, palette='Set2')\n",
    "        ax2.set_ylabel('Reaction Time (ms)', fontsize=12, fontweight='bold')\n",
    "        ax2.set_xlabel('Trial Type', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Reaction Time Distribution by Trial Type', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Reaction Time Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reaction time distribution and trends\n",
    "if files and len(rt_data) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # RT histogram\n",
    "    ax1 = axes[0]\n",
    "    ax1.hist(rt_data, bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "    ax1.axvline(mean_rt, color='red', linestyle='--', linewidth=2, label=f'Mean: {mean_rt:.1f} ms')\n",
    "    ax1.axvline(median_rt, color='green', linestyle='--', linewidth=2, label=f'Median: {median_rt:.1f} ms')\n",
    "    ax1.set_xlabel('Reaction Time (ms)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Reaction Time Distribution', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # RT over time (check for fatigue/learning)\n",
    "    ax2 = axes[1]\n",
    "    rt_trials = df_trials[df_trials['reaction_time_ms'].notna()].copy()\n",
    "    ax2.scatter(rt_trials['trial_index'], rt_trials['reaction_time_ms'], \n",
    "               alpha=0.5, color='#3498db', s=50)\n",
    "    \n",
    "    # Add trend line\n",
    "    z = np.polyfit(rt_trials['trial_index'], rt_trials['reaction_time_ms'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    ax2.plot(rt_trials['trial_index'], p(rt_trials['trial_index']), \n",
    "            \"r--\", linewidth=2, label=f'Trend: {z[0]:.2f} ms/trial')\n",
    "    \n",
    "    ax2.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Reaction Time (ms)', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Reaction Time Over Trials', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Interpretation\n",
    "    if z[0] > 5:\n",
    "        print(\"\\n‚ö†Ô∏è  RT increasing over time - possible fatigue effect\")\n",
    "    elif z[0] < -5:\n",
    "        print(\"\\n‚úì RT decreasing over time - possible practice effect\")\n",
    "    else:\n",
    "        print(\"\\n‚úì RT stable over time - consistent performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Response Pattern Timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize response patterns over time\n",
    "if files:\n",
    "    fig, ax = plt.subplots(figsize=(14, 4))\n",
    "    \n",
    "    # Color code by outcome\n",
    "    colors = []\n",
    "    for _, row in df_trials.iterrows():\n",
    "        if row['response'] == 0:\n",
    "            colors.append('#95a5a6')  # Gray for no response\n",
    "        elif row['correct'] == 1:\n",
    "            colors.append('#2ecc71')  # Green for correct\n",
    "        else:\n",
    "            colors.append('#e74c3c')  # Red for incorrect\n",
    "    \n",
    "    ax.scatter(df_trials['trial_index'], df_trials['trial_type'].astype('category').cat.codes,\n",
    "              c=colors, s=100, alpha=0.7, edgecolors='black', linewidth=0.5)\n",
    "    \n",
    "    ax.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax.set_ylabel('Trial Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_yticks(range(len(df_trials['trial_type'].unique())))\n",
    "    ax.set_yticklabels(sorted(df_trials['trial_type'].unique()))\n",
    "    ax.set_title('Response Pattern Timeline', fontsize=14, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Add legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#2ecc71', label='Correct'),\n",
    "        Patch(facecolor='#e74c3c', label='Incorrect'),\n",
    "        Patch(facecolor='#95a5a6', label='No Response')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Webcam Tracking Analysis\n",
    "\n",
    "This section analyzes attention-related metrics from webcam tracking (if enabled)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Session Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display tracking session summary\n",
    "if files and df_session is not None:\n",
    "    print(\"\\nüëÅÔ∏è  Webcam Tracking Session Summary\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    session_summary = pd.DataFrame({\n",
    "        'Metric': [\n",
    "            'Total Blinks',\n",
    "            'Overall Blink Rate (blinks/sec)',\n",
    "            'Total Frames Tracked',\n",
    "            'Mean Head Stability',\n",
    "            'Engagement Score (0-1)',\n",
    "            'Fatigue Indicator',\n",
    "            'Session Duration (sec)'\n",
    "        ],\n",
    "        'Value': [\n",
    "            df_session['total_blinks'].values[0],\n",
    "            f\"{df_session['overall_blink_rate'].values[0]:.3f}\",\n",
    "            df_session['total_frames_tracked'].values[0],\n",
    "            f\"{df_session['mean_head_stability'].values[0]:.6f}\",\n",
    "            f\"{df_session['engagement_score'].values[0]:.3f}\",\n",
    "            f\"{df_session['fatigue_indicator'].values[0]:.3f}\",\n",
    "            f\"{df_session['session_duration_seconds'].values[0]:.1f}\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    display(session_summary)\n",
    "    \n",
    "    # Interpretation\n",
    "    engagement = df_session['engagement_score'].values[0]\n",
    "    fatigue = df_session['fatigue_indicator'].values[0]\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    if engagement > 0.95:\n",
    "        print(\"  ‚úì High engagement - participant maintained good attention\")\n",
    "    elif engagement > 0.85:\n",
    "        print(\"  ‚ö†Ô∏è  Moderate engagement - some head movement detected\")\n",
    "    else:\n",
    "        print(\"  ‚ùå Low engagement - significant head movement or looking away\")\n",
    "    \n",
    "    if fatigue > 0.2:\n",
    "        print(\"  ‚ö†Ô∏è  Fatigue detected - blink rate increased over session\")\n",
    "    elif fatigue < -0.2:\n",
    "        print(\"  ‚úì Alertness increased over session\")\n",
    "    else:\n",
    "        print(\"  ‚úì Consistent alertness throughout session\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No tracking data available. Enable webcam tracking in config.json to see these metrics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Blink Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze blink patterns\n",
    "if files and df_trials['blink_count'].notna().any():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Blink rate over trials\n",
    "    ax1 = axes[0]\n",
    "    trials_with_tracking = df_trials[df_trials['blink_rate'].notna()].copy()\n",
    "    \n",
    "    ax1.plot(trials_with_tracking['trial_index'], trials_with_tracking['blink_rate'], \n",
    "            marker='o', linewidth=2, markersize=6, color='#9b59b6', alpha=0.7)\n",
    "    ax1.axhline(y=trials_with_tracking['blink_rate'].mean(), \n",
    "               color='red', linestyle='--', linewidth=2, \n",
    "               label=f\"Mean: {trials_with_tracking['blink_rate'].mean():.2f} blinks/sec\")\n",
    "    \n",
    "    ax1.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Blink Rate (blinks/sec)', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Blink Rate Over Trials', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Blink count distribution\n",
    "    ax2 = axes[1]\n",
    "    ax2.hist(trials_with_tracking['blink_count'], bins=range(0, int(trials_with_tracking['blink_count'].max())+2),\n",
    "            color='#9b59b6', alpha=0.7, edgecolor='black')\n",
    "    ax2.set_xlabel('Blinks per Trial', fontsize=12, fontweight='bold')\n",
    "    ax2.set_ylabel('Frequency', fontsize=12, fontweight='bold')\n",
    "    ax2.set_title('Blink Count Distribution', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # First half vs second half comparison (fatigue check)\n",
    "    midpoint = len(trials_with_tracking) // 2\n",
    "    first_half_blinks = trials_with_tracking.iloc[:midpoint]['blink_rate'].mean()\n",
    "    second_half_blinks = trials_with_tracking.iloc[midpoint:]['blink_rate'].mean()\n",
    "    \n",
    "    print(f\"\\nüìä Blink Rate Comparison:\")\n",
    "    print(f\"  First half:  {first_half_blinks:.3f} blinks/sec\")\n",
    "    print(f\"  Second half: {second_half_blinks:.3f} blinks/sec\")\n",
    "    print(f\"  Change:      {((second_half_blinks - first_half_blinks) / first_half_blinks * 100):.1f}%\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No blink tracking data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Head Movement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze head movement and stability\n",
    "if files and df_trials['head_movement_variance'].notna().any():\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Head stability over trials\n",
    "    ax1 = axes[0]\n",
    "    trials_with_tracking = df_trials[df_trials['head_movement_variance'].notna()].copy()\n",
    "    \n",
    "    ax1.plot(trials_with_tracking['trial_index'], trials_with_tracking['head_movement_variance'],\n",
    "            marker='o', linewidth=2, markersize=6, color='#e67e22', alpha=0.7)\n",
    "    ax1.axhline(y=trials_with_tracking['head_movement_variance'].mean(),\n",
    "               color='red', linestyle='--', linewidth=2,\n",
    "               label=f\"Mean: {trials_with_tracking['head_movement_variance'].mean():.6f}\")\n",
    "    \n",
    "    ax1.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "    ax1.set_ylabel('Head Movement Variance', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('Head Stability Over Trials (Lower = More Stable)', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Looking away events\n",
    "    ax2 = axes[1]\n",
    "    if trials_with_tracking['looking_away_count'].sum() > 0:\n",
    "        ax2.bar(trials_with_tracking['trial_index'], trials_with_tracking['looking_away_count'],\n",
    "               color='#e74c3c', alpha=0.7, edgecolor='black')\n",
    "        ax2.set_xlabel('Trial Number', fontsize=12, fontweight='bold')\n",
    "        ax2.set_ylabel('Looking Away Events', fontsize=12, fontweight='bold')\n",
    "        ax2.set_title('Looking Away Events per Trial', fontsize=14, fontweight='bold')\n",
    "        ax2.grid(alpha=0.3)\n",
    "    else:\n",
    "        ax2.text(0.5, 0.5, 'No looking away events detected\\n‚úì Good attention maintenance',\n",
    "                ha='center', va='center', transform=ax2.transAxes,\n",
    "                fontsize=14, fontweight='bold', color='#2ecc71')\n",
    "        ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No head movement tracking data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Frame-Level Tracking Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize frame-level tracking data\n",
    "if files and df_frames is not None:\n",
    "    print(f\"\\nüìπ Frame-level tracking: {len(df_frames)} frames analyzed\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Head position over time (X-Y scatter)\n",
    "    ax1 = axes[0, 0]\n",
    "    scatter = ax1.scatter(df_frames['head_x'], df_frames['head_y'], \n",
    "                         c=df_frames['trial_index'], cmap='viridis', \n",
    "                         alpha=0.5, s=10)\n",
    "    ax1.set_xlabel('Head X Position', fontsize=11, fontweight='bold')\n",
    "    ax1.set_ylabel('Head Y Position', fontsize=11, fontweight='bold')\n",
    "    ax1.set_title('Head Position Heatmap', fontsize=12, fontweight='bold')\n",
    "    plt.colorbar(scatter, ax=ax1, label='Trial Index')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Eye aspect ratio over time (blink detection)\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.plot(df_frames['timestamp'], df_frames['left_eye_aspect_ratio'], \n",
    "            label='Left Eye', alpha=0.7, linewidth=1)\n",
    "    ax2.plot(df_frames['timestamp'], df_frames['right_eye_aspect_ratio'],\n",
    "            label='Right Eye', alpha=0.7, linewidth=1)\n",
    "    ax2.axhline(y=0.25, color='red', linestyle='--', alpha=0.5, label='Blink Threshold')\n",
    "    ax2.set_xlabel('Time (seconds)', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Eye Aspect Ratio', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Eye Openness Over Time', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # Head pitch/yaw over time\n",
    "    ax3 = axes[1, 0]\n",
    "    ax3.plot(df_frames['timestamp'], df_frames['head_pitch'], \n",
    "            label='Pitch (up/down)', alpha=0.7, linewidth=1.5)\n",
    "    ax3.plot(df_frames['timestamp'], df_frames['head_yaw'],\n",
    "            label='Yaw (left/right)', alpha=0.7, linewidth=1.5)\n",
    "    ax3.set_xlabel('Time (seconds)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_ylabel('Angle (degrees)', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Head Orientation Over Time', fontsize=12, fontweight='bold')\n",
    "    ax3.legend()\n",
    "    ax3.grid(alpha=0.3)\n",
    "    \n",
    "    # Blink events timeline\n",
    "    ax4 = axes[1, 1]\n",
    "    blink_frames = df_frames[df_frames['is_blinking'] == True]\n",
    "    ax4.scatter(blink_frames['timestamp'], blink_frames['trial_index'],\n",
    "               color='#e74c3c', s=50, alpha=0.6, marker='|', linewidths=2)\n",
    "    ax4.set_xlabel('Time (seconds)', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Trial Index', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title(f'Blink Events Timeline ({len(blink_frames)} blinks)', fontsize=12, fontweight='bold')\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No frame-level tracking data available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Combined Analysis: Performance vs Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between tracking metrics and performance\n",
    "if files and df_trials['blink_count'].notna().any():\n",
    "    # Create subset with tracking data\n",
    "    tracked_trials = df_trials[df_trials['blink_count'].notna()].copy()\n",
    "    \n",
    "    # Calculate correlations\n",
    "    print(\"\\nüîó Correlation between Tracking Metrics and Performance\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    correlations = {\n",
    "        'Blink Rate vs Accuracy': tracked_trials[['blink_rate', 'correct']].corr().iloc[0, 1],\n",
    "        'Head Movement vs Accuracy': tracked_trials[['head_movement_variance', 'correct']].corr().iloc[0, 1],\n",
    "        'Looking Away vs Accuracy': tracked_trials[['looking_away_count', 'correct']].corr().iloc[0, 1]\n",
    "    }\n",
    "    \n",
    "    # Also check RT correlations if available\n",
    "    rt_tracked = tracked_trials[tracked_trials['reaction_time_ms'].notna()]\n",
    "    if len(rt_tracked) > 0:\n",
    "        correlations['Blink Rate vs RT'] = rt_tracked[['blink_rate', 'reaction_time_ms']].corr().iloc[0, 1]\n",
    "        correlations['Head Movement vs RT'] = rt_tracked[['head_movement_variance', 'reaction_time_ms']].corr().iloc[0, 1]\n",
    "    \n",
    "    corr_df = pd.DataFrame(list(correlations.items()), columns=['Relationship', 'Correlation'])\n",
    "    corr_df['Correlation'] = corr_df['Correlation'].round(3)\n",
    "    display(corr_df)\n",
    "    \n",
    "    print(\"\\nüí° Interpretation:\")\n",
    "    print(\"  Correlation > 0.3: Moderate positive relationship\")\n",
    "    print(\"  Correlation < -0.3: Moderate negative relationship\")\n",
    "    print(\"  |Correlation| < 0.3: Weak or no relationship\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Not enough tracking data for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Error Analysis with Tracking Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze errors in context of tracking data\n",
    "if files and df_trials['blink_count'].notna().any():\n",
    "    tracked_trials = df_trials[df_trials['blink_count'].notna()].copy()\n",
    "    \n",
    "    # Compare tracking metrics for correct vs incorrect trials\n",
    "    correct_trials = tracked_trials[tracked_trials['correct'] == 1]\n",
    "    incorrect_trials = tracked_trials[tracked_trials['correct'] == 0]\n",
    "    \n",
    "    if len(incorrect_trials) > 0:\n",
    "        print(\"\\n‚ùå Error Analysis with Tracking Context\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        comparison = pd.DataFrame({\n",
    "            'Metric': ['Blink Rate', 'Head Movement', 'Looking Away Events'],\n",
    "            'Correct Trials': [\n",
    "                f\"{correct_trials['blink_rate'].mean():.3f}\",\n",
    "                f\"{correct_trials['head_movement_variance'].mean():.6f}\",\n",
    "                f\"{correct_trials['looking_away_count'].mean():.2f}\"\n",
    "            ],\n",
    "            'Incorrect Trials': [\n",
    "                f\"{incorrect_trials['blink_rate'].mean():.3f}\",\n",
    "                f\"{incorrect_trials['head_movement_variance'].mean():.6f}\",\n",
    "                f\"{incorrect_trials['looking_away_count'].mean():.2f}\"\n",
    "            ]\n",
    "        })\n",
    "        \n",
    "        display(comparison)\n",
    "        \n",
    "        # Visualize\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "        \n",
    "        metrics = ['blink_rate', 'head_movement_variance', 'looking_away_count']\n",
    "        titles = ['Blink Rate', 'Head Movement Variance', 'Looking Away Count']\n",
    "        \n",
    "        for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "            ax = axes[idx]\n",
    "            data_to_plot = [correct_trials[metric].dropna(), incorrect_trials[metric].dropna()]\n",
    "            ax.boxplot(data_to_plot, labels=['Correct', 'Incorrect'])\n",
    "            ax.set_ylabel(title, fontweight='bold')\n",
    "            ax.set_title(f'{title}\\nby Trial Outcome', fontweight='bold')\n",
    "            ax.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\n‚úì No errors detected - perfect performance!\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  Not enough tracking data for error analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Trial-by-Trial Deep Dive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive table for detailed trial inspection\n",
    "if files:\n",
    "    print(\"\\nüîç Trial-by-Trial Data (showing first 20 trials)\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Select relevant columns\n",
    "    display_cols = ['trial_index', 'trial_type', 'stimulus', 'response', 'correct', 'reaction_time_ms']\n",
    "    \n",
    "    # Add tracking columns if available\n",
    "    if df_trials['blink_count'].notna().any():\n",
    "        display_cols.extend(['blink_count', 'blink_rate', 'head_movement_variance', 'looking_away_count'])\n",
    "    \n",
    "    display(df_trials[display_cols].head(20))\n",
    "    \n",
    "    print(\"\\nüí° Tip: You can filter and sort this data to investigate specific patterns.\")\n",
    "    print(\"   Example: df_trials[df_trials['correct'] == 0] shows only error trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Export & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate final summary report\n",
    "if files:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"üìã FINAL SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìÅ Session: {files['trial_data'].name}\")\n",
    "    print(f\"\\nüìä BEHAVIORAL PERFORMANCE:\")\n",
    "    print(f\"  ‚Ä¢ Total Trials: {total_trials}\")\n",
    "    print(f\"  ‚Ä¢ Overall Accuracy: {overall_accuracy:.1f}%\")\n",
    "    print(f\"  ‚Ä¢ Response Rate: {response_rate:.1f}%\")\n",
    "    print(f\"  ‚Ä¢ Mean RT: {mean_rt:.1f} ms\")\n",
    "    \n",
    "    if df_session is not None:\n",
    "        print(f\"\\nüëÅÔ∏è  ATTENTION METRICS:\")\n",
    "        print(f\"  ‚Ä¢ Total Blinks: {df_session['total_blinks'].values[0]}\")\n",
    "        print(f\"  ‚Ä¢ Blink Rate: {df_session['overall_blink_rate'].values[0]:.3f} blinks/sec\")\n",
    "        print(f\"  ‚Ä¢ Engagement Score: {df_session['engagement_score'].values[0]:.3f}\")\n",
    "        print(f\"  ‚Ä¢ Fatigue Indicator: {df_session['fatigue_indicator'].values[0]:.3f}\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Analysis complete!\")\n",
    "    print(f\"\\nüí° Next steps:\")\n",
    "    print(f\"  ‚Ä¢ Modify cells above to explore specific patterns\")\n",
    "    print(f\"  ‚Ä¢ Export figures using plt.savefig('filename.png')\")\n",
    "    print(f\"  ‚Ä¢ Compare with other sessions by loading different files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
